{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References - The text in this notebook is mostly copied and summarized from the references below\n",
    "\n",
    "1. Generative Adversarial Nets - Ian Goodfeloow et al.\n",
    "2. Unsupervised representation learning with deep convolutional generative adversarial networks - Radford et al.\n",
    "3. Least squares generative adversarial networks - Mao et al.\n",
    "4. Wasserstein generative adversarial networks - Arjovsky et al.\n",
    "5. Generative Adversarial Networks - Jason Brownlee \n",
    "6. Deep Learning with Python - Francois Chollet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Modelling\n",
    "\n",
    "Generative modelling is an unsupervised task in machine learning that aims to identify patterns and regularaties in the input domain. The training of such models is done in such a way that the samples generated by the trained model will be sufficiently close to the samples available in the input domain. Thus generative modelling in essence is a technique of generating 'fake' samples that are hard to identify as 'fake'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised vs Unsupervised\n",
    "\n",
    "A typical machine learning problem involves using a model to make a prediction, e.g. predictive\n",
    "modeling. This requires a training dataset that is used to train a model, comprised of multiple\n",
    "examples, called samples, each with input variables (X) and output class labels (y). A model is\n",
    "trained by showing examples of inputs, having it predict outputs, and correcting the model to\n",
    "make the outputs more like the expected outputs. \n",
    "\n",
    "This correction of the model is generally referred to as a supervised form of learning, or\n",
    "supervised learning. It is supervised because there is a real expected outcome to which a\n",
    "prediction is compared.\n",
    "\n",
    "This lack of correction is generally referred to as an unsupervised form of learning, or\n",
    "unsupervised learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminative vs Generative Modelling\n",
    "\n",
    "In supervised learning, we may be interested in developing a model to predict a class label\n",
    "given an example of input variables. This predictive modeling task is called classification.\n",
    "Classification is also traditionally referred to as discriminative modeling. \n",
    "\n",
    "This is because a model must discriminate examples of input variables across classes; it must\n",
    "choose or make a decision as to what class a given example belongs.\n",
    "\n",
    "Alternately, unsupervised models that summarize the distribution of input variables may be\n",
    "able to be used to create or generate new examples in the input distribution. As such, these\n",
    "types of models are referred to as generative models.\n",
    "\n",
    "For example, a single variable may have a known data distribution, such as a Gaussian\n",
    "distribution, or bell shape. A generative model may be able to sufficiently summarize this data\n",
    "distribution, and then be used to generate new examples that plausibly fit into the distribution\n",
    "of the input variable.\n",
    "\n",
    "In fact, a really good generative model may be able to generate new examples that are not\n",
    "just plausible, but __indistinguishable__ from real examples from the problem domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of Generative Models\n",
    "\n",
    "1. Naive Bayes is an example of a generative model that is more often used as a discriminative model. For example, Naive Bayes works by summarizing the probability distribution of each input variable and the output class. When a prediction is made, the probability for each possible outcome is calculated for each variable, the independent probabilities are combined, and the most likely outcome is predicted. Used in reverse, the probability distributions for each variable can be sampled to generate new plausible (independent) feature values.\n",
    "2. Latent Dirichlet Allocation, or LDA\n",
    "3. Gaussian Mixture Model, or GMM. \n",
    "\n",
    "Deep learning methods can be used as generative models. Two popular examples include:\n",
    "1. Restricted Boltzmann Machine, or RBM\n",
    "2. Deep Belief Network, or DBN. \n",
    "\n",
    "Two modern examples of deep learning generative modeling algorithms include:\n",
    "1. Variational Autoencoder, or VAE \n",
    "2. Generative Adversarial Network, or GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Network\n",
    "\n",
    "GANs tackle the unsupervised task of Generative modelling in a unique way. GANs make the training of a generative model into a supervised learning task by introducing two sub models. \n",
    "\n",
    "    1. Generator: This model generates new samples.\n",
    "    2. Discriminator: This model tries to classify the samples generated by the generator as either real (coming from the input domain) or fake (coming from the generator)\n",
    "\n",
    "The two models are then trained together in an adversarial zero-sum game until the discriminator model is unable separate generated samples from real samples at least half of the time. At this point in training the generator model should be able to produce sufficiently good 'fake' samples.\n",
    "\n",
    "Generative adversarial networks are based on a __game theoretic__ scenario in which\n",
    "the generator network must compete against an __adversary__. The generator network\n",
    "directly produces samples. Its adversary, the discriminator network, attempts to\n",
    "distinguish between samples drawn from the training data and samples drawn from\n",
    "the generator.\n",
    "\n",
    "### The Generator Model\n",
    "The generator model takes a fixed-length random vector as input and generates a sample in the\n",
    "domain, such as an image. \n",
    "\n",
    "-> A vector is drawn randomly from a __Gaussian distribution__ and is\n",
    "used to seed or source of noise for the generative process. To be clear, the input is a vector of\n",
    "random numbers. It is not an image or a flattened image and has no meaning other than the\n",
    "meaning applied by the generator model. \n",
    "\n",
    "-> After training, points in this multidimensional vector\n",
    "space will correspond to points in the problem domain, forming a compressed representation\n",
    "of the data distribution. This vector space is referred to as a __latent space__, or a vector space\n",
    "comprised of latent variables.\n",
    "\n",
    "-> __Latent variables__, or hidden variables, are those variables that are\n",
    "important for a domain but are __not directly observable__. A latent space provides a compression or high-level concepts of the\n",
    "observed raw data such as the input data distribution.\n",
    "\n",
    "### The Discriminator Model\n",
    "The discriminator model takes an example from the problem domain as input (real or generated)\n",
    "and predicts a binary class label of real or fake (generated). The real example comes from the\n",
    "training dataset. The generated examples are output by the generator model. The discriminator\n",
    "is a normal classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN as a Two Player Game\n",
    "Generative modeling is an unsupervised learning problem. A clever property of the GAN architecture is that the training of the generative model\n",
    "is framed as a supervised learning problem. The two models, the generator and discriminator,\n",
    "are trained together. The generator generates a batch of samples, and these, along with real\n",
    "examples from the domain, are provided to the discriminator and classified as real or fake.\n",
    "The discriminator is then updated to get better at discriminating real and fake samples\n",
    "in the next round, and importantly, the generator is updated based on how well, or not, the\n",
    "generated samples fooled the discriminator.\n",
    "\n",
    "We can think of the generator as being like a counterfeiter, trying to make fake\n",
    "money, and the discriminator as being like police, trying to allow legitimate money\n",
    "and catch counterfeit money. To succeed in this game, the counterfeiter must learn\n",
    "to make money that is indistinguishable from genuine money, and the generator\n",
    "network must learn to create samples that are drawn from the same distribution as\n",
    "the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, the two models are competing against each other. They are adversarial in the\n",
    "game theory sense and are playing a zero-sum game.\n",
    "\n",
    "Because the GAN framework can naturally be analyzed with the tools of game\n",
    "theory, we call GANs “adversarial”.\n",
    "— __NIPS 2016 Tutorial: Generative Adversarial Networks, 2016.__\n",
    "\n",
    "In this case, zero-sum means that when the discriminator successfully identifies real and\n",
    "fake samples, it is rewarded and no change is needed to the model parameters, whereas the\n",
    "generator is penalized with large updates to model parameters. Alternately, when the generator\n",
    "fools the discriminator, it is rewarded and no change is needed to the model parameters, but\n",
    "the discriminator is penalized and its model parameters are updated.\n",
    "At a limit, the generator generates perfect replicas from the input domain every time, and\n",
    "the discriminator cannot tell the difference and predicts unsure (e.g. 50% for real and fake) in\n",
    "every case. This is just an example of an idealized case; we do not need to get to this point to\n",
    "arrive at a useful generator model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANs and Convolutional Neural Networks\n",
    "\n",
    "GANs typically work with image data and use Convolutional Neural Networks, or CNNs, as\n",
    "the generator and discriminator models. The reason for this may be both because the first\n",
    "description of the technique was in the field of computer vision and it used image data, and\n",
    "because of the remarkable progress that has been seen in recent years using CNNs more generally\n",
    "to achieve state-of-the-art results on a suite of computer vision tasks such as object detection\n",
    "and face recognition.\n",
    "Modeling image data means that the latent space, the input to the generator, provides a\n",
    "compressed representation of the set of images or photographs used to train the model. It also\n",
    "means that the generator generates new images, providing an output that can be easily viewed\n",
    "and assessed by developers or users of the model. It may be this fact above others, the ability to\n",
    "visually assess the quality of the generated output, that has both led to the focus of computer\n",
    "vision applications with CNNs and on the massive leaps in the capability of GANs as compared\n",
    "to other generative models, deep-learning-based or otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Interest Point\n",
    "\n",
    "__GANs provide a path to sophisticated domain-specific data augmentation and a solution\n",
    "to problems that require a generative solution, such as image-to-image translation. This could imply further practical use cases other than image to image translation. From stronger pseudorandom number generators based on chaotic maps to solving PDE's that require both interpolation and extrapolation for solutions.__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6364572a05610c145f7348150b927d4800d35aff954ebf5201318569ffcf301"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
